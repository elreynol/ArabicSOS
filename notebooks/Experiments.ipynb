{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn_crfsuite.metrics import sequence_accuracy_score\n",
    "\n",
    "from scripts.feature_extractor import char_to_features, sent_to_features\n",
    "from scripts.preprocessor import clean_arabic\n",
    "from scripts.postprocessor import get_human_readable_segmentation, _humanify_sentence, _humanify_word\n",
    "\n",
    "\n",
    "feature_codes_1 = ['chr_position', 'minus5', 'minus4', 'minus3', 'minus2', 'minus1', 'focus',\n",
    "                 'plus1', 'plus2', 'plus3', 'plus4', 'plus5', 'next2letters', \n",
    "                 'prev2letters', 'prev_word_suffix', 'following_word_prefix',\n",
    "                 'focus_word_prefix', 'focus_word_suffix']\n",
    "\n",
    "feature_codes_2 = ['minus5', 'minus4', 'minus3', 'minus2', 'minus1', 'focus',\n",
    "                 'plus1', 'plus2', 'plus3', 'plus4', 'plus5',\n",
    "                   'prev_word_minus1', 'prev_word_minus2', 'prev_word_minus3',\n",
    "                  'following_word_plus0', 'following_word_plus1', 'following_word_plus2']\n",
    "\n",
    "feature_codes = {'fc1': feature_codes_1, 'fc2': feature_codes_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featureset(in_tsv_path, raw_col, seg_col, feature_code, out_file_path):\n",
    "    \"\"\"\n",
    "    This function takes as input a tsv file which contains the raw and segmented form of sentence.\n",
    "    raw_col is the name of the column containing raw sentences\n",
    "    seg_col is the name of the column containing seg sentences\n",
    "    feature_code = 'fc1' or 'fc2'\n",
    "    The path of the output folder. It will append '_{feature_code}' to the input file name to produce\n",
    "    the output file name\n",
    "    \"\"\"\n",
    "    feature_names = feature_codes[feature_code]\n",
    "    \n",
    "    with open(in_tsv_path) as infile, open(out_file_path, 'w') as outfile:\n",
    "        freader = csv.DictReader(infile, delimiter='\\t')\n",
    "        fwriter = csv.writer(outfile, delimiter='\\t')\n",
    "        fwriter.writerow([\"file\", \"sentence_no\", \"word_no\", \"word\", \"char\"] + feature_names + [\"char_label\"])\n",
    "        for line_no, line in enumerate(freader):\n",
    "            raw_sent = line[raw_col]\n",
    "            sent_feats = sent_to_features(raw_sent, feature_names)\n",
    "            if seg_col:\n",
    "                seg_sent = line[seg_col]\n",
    "                sent_labels = sent_to_labels(seg_sent)\n",
    "            \n",
    "            sent_feats, sent_labels = sent_to_features(raw_sent, feature_names), sent_to_labels(seg_sent)\n",
    "            for word_no, (word, word_feats, word_labels) in enumerate(zip(raw_sent.split(), sent_feats, sent_labels)):\n",
    "                for char, char_feats, char_label in zip(word, word_feats, word_labels):\n",
    "                    fwriter.writerow([line['file'], line_no, word_no, word, char] + char_feats + [char_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_features(sentences, feature_code):\n",
    "    feature_names = feature_codes[feature_code]\n",
    "    features = []\n",
    "    for sentence_no, sentence in enumerate(sentences):\n",
    "        sent_feats =sent_to_features(sentence, feature_names)\n",
    "        for word_no, (word, word_feats)  in enumerate(zip(sentence.split(), sent_feats)):\n",
    "            for char, char_feats in zip(word, word_feats):\n",
    "                features.append([sentence_no, word_no] + char_feats)\n",
    "    columns = ['sentence_no', 'word_no'] + feature_names\n",
    "    feature_frame = pd.DataFrame(features, columns=columns)\n",
    "    return feature_frame\n",
    "\n",
    "def segment(sentences, model, fc):\n",
    "    features = create_prediction_features(sentences, fc)\n",
    "    features['predictions'] = model.predict(features[feature_codes[fc]]).astype(int)\n",
    "    breakpoints = features.groupby(['sentence_no', 'word_no'])['predictions'].apply(list)\n",
    "    segmented_sentences = get_human_readable_segmentation(sentences, breakpoints)\n",
    "    return segmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"data/combined/results/ManarCorrected.result\", sep='\\t')\n",
    "data2 = pd.read_csv(\"data/combined/results/Classical.result\", sep='\\t')\n",
    "datas = [data1, data2]\n",
    "model_folder = 'data/segmenter/models'\n",
    "models = {'ManarPlusClassical': 'catboost_fc1_1.model',\n",
    "             'ManarPlusClassicalSubstandard': 'catboost_fc1_1_sso.model',\n",
    "             'ManarOnly': 'catboost_fc1_ManarOnly.model',\n",
    "             'ManarOnlySubstandard': 'catboost_fc1_ManarOnly_sso.model'}\n",
    "\n",
    "models = {'ManarPlusClassical': 'catboost_fc1_Train4.model'}\n",
    "raw_columns = ['original_raw', 'sso_raw', 'sso_raw_standardized']\n",
    "\n",
    "data = data2\n",
    "raw_columns = ['original_raw', 'sso_raw', 'sso_raw_standardized']\n",
    "for col in raw_columns:\n",
    "    for model_name in models:\n",
    "        new_col = col + '_' + model_name + '_segmented'\n",
    "        model = CatBoostClassifier()\n",
    "        model.load_model(os.path.join(model_folder, models[model_name]))\n",
    "        data[new_col] = segment(data[col], model, 'fc1')\n",
    "        \n",
    "data.to_csv('data/combined/results/test2result4.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f1064bdc908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/combined/results/test1result.tsv\", sep='\\t')\n",
    "model = CatBoostClassifier()\n",
    "model.load_model(\"data/segmenter/models/catboost_fc1_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = ['original_raw', 'sso_raw', 'sso_raw_standardized']\n",
    "for col in raw_columns:\n",
    "    new_col = col + '_segmented'\n",
    "    data[new_col] = segment(data[col], model, 'fc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/combined/results/test1result_updated.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/combined/results/Classical.result', sep='\\t', index=False)\n",
    "data.to_csv('data/combined/results/Manar.result', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
